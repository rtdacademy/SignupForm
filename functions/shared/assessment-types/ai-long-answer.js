/**
 * Reusable AI Long Answer Assessment Module
 * This module provides a factory function to create AI-powered long answer assessments
 * Course developers can import this and configure it with their specific prompts and settings
 * 
 * ARCHITECTURE:
 * =============
 * This backend module works in conjunction with the frontend component:
 * - Frontend: src/FirebaseCourses/components/assessments/AILongAnswerQuestion/index.js
 * - Backend: This module creates cloud functions that the frontend calls
 * - Configuration: Set parameters in course-specific files like functions/courses/2/02-momentum-one-dimension/assessments.js
 * 
 * The frontend component automatically handles:
 * - Displaying questions with rubrics generated by this module
 * - Student answer submission with rich text support
 * - AI-powered evaluation and scoring
 * - Detailed feedback display per rubric criterion
 * - AI chat integration with answer context
 * 
 * WORKFLOW:
 * =========
 * 1. Configure this module in your course assessment file
 * 2. Deploy the cloud function
 * 3. Frontend component calls your cloud function to generate questions with rubrics
 * 4. Students write answers using the rich text editor
 * 5. AI evaluates answers against the rubric criteria
 * 6. Students receive detailed scoring and feedback
 * 
 * USAGE:
 * ======
 * 
 * ```javascript
 * const { createAILongAnswer } = require('../../../shared/assessment-types/ai-long-answer');
 * 
 * exports.yourFunctionName = createAILongAnswer({
 *   // Configuration object - see ACCEPTED PARAMETERS below
 * });
 * ```
 * 
 * ACCEPTED PARAMETERS:
 * ===================
 * 
 * Core Configuration:
 * - prompts: {Object} - Prompts for different difficulty levels
 *   - beginner: {string} - Prompt for beginner-level questions with rubrics
 *   - intermediate: {string} - Prompt for intermediate-level questions with rubrics
 *   - advanced: {string} - Prompt for advanced-level questions with rubrics
 * 
 * Rubric Settings:
 * - rubricCriteria: {number} - Number of rubric criteria (1-6, default: 3)
 * - pointsPerCriterion: {Array<number>} - Points for each criterion (default: auto-distributed)
 * - totalPoints: {number} - Total points for the question (default: 10)
 * 
 * Word Limits:
 * - wordLimits: {Object} - Word count constraints
 *   - min: {number} - Minimum words (default: 50)
 *   - max: {number} - Maximum words (default: 500)
 * 
 * Activity Settings:
 * - activityType: {string} - Type of activity ('lesson', 'assignment', 'exam', 'lab')
 * - maxAttempts: {number} - Maximum attempts allowed (default: from course config)
 * - showRubric: {boolean} - Whether to show rubric to students (default: true)
 * - showWordCount: {boolean} - Whether to show word count (default: true)
 * - showHints: {boolean} - Whether to enable hints (default: false)
 * - theme: {string} - Color theme ('blue', 'green', 'purple', 'amber')
 * - allowDifficultySelection: {boolean} - Allow students to select difficulty
 * 
 * AI Chat Settings:
 * - enableAIChat: {boolean} - Whether to show AI chat button for students
 * - aiChatContext: {string} - Additional context about the question to help AI tutors
 * 
 * AI Generation Settings:
 * - aiSettings: {Object} - AI generation parameters
 *   - temperature: {number} - AI creativity (0-1, default: 0.8)
 *   - topP: {number} - Nucleus sampling (0-1, default: 0.85)
 *   - topK: {number} - Top-K sampling (default: 40)
 * 
 * Content Settings:
 * - katexFormatting: {boolean} - Enable LaTeX math formatting (default: true)
 * - subject: {string} - Subject name for context
 * - gradeLevel: {number} - Grade level for context
 * - topic: {string} - Topic name for context
 * - learningObjectives: {Array<string>} - Learning objectives for context
 * 
 * Fallback Questions:
 * - fallbackQuestions: {Array<Object>} - Backup questions if AI generation fails
 *   Each fallback question should have:
 *   - questionText: {string}
 *   - rubric: {Array<Object>} - Array of {criterion, points, description} objects
 *   - maxPoints: {number}
 *   - wordLimit: {Object} - {min, max}
 *   - sampleAnswer: {string}
 *   - difficulty: {string}
 * 
 * EXAMPLE USAGE:
 * ==============
 * 
 * ```javascript
 * exports.course2_momentum_longAnswer = createAILongAnswer({
 *   prompts: {
 *     beginner: "Create a beginner physics long answer question about momentum...",
 *     intermediate: "Create an intermediate physics long answer question...",
 *     advanced: "Create an advanced physics long answer question..."
 *   },
 *   activityType: 'assignment',
 *   totalPoints: 10,
 *   rubricCriteria: 4,
 *   wordLimits: { min: 100, max: 300 },
 *   enableAIChat: true,
 *   aiChatContext: "This question tests conceptual understanding of momentum conservation.",
 *   katexFormatting: true,
 *   maxAttempts: 2,
 *   theme: 'blue',
 *   subject: 'Physics 30',
 *   gradeLevel: 12,
 *   topic: 'Momentum Conservation',
 *   fallbackQuestions: [
 *     {
 *       questionText: "Explain the principle of conservation of momentum...",
 *       rubric: [
 *         { criterion: "Definition", points: 3, description: "Correctly defines momentum" },
 *         { criterion: "Conservation Law", points: 4, description: "Explains conservation principle" },
 *         { criterion: "Examples", points: 3, description: "Provides relevant examples" }
 *       ],
 *       maxPoints: 10,
 *       wordLimit: { min: 100, max: 300 },
 *       sampleAnswer: "Momentum is defined as...",
 *       difficulty: 'intermediate'
 *     }
 *   ]
 * });
 * ```
 */

const { onCall } = require('firebase-functions/v2/https');
const { genkit } = require('genkit/beta');
const { googleAI } = require('@genkit-ai/googleai');
const { z } = require('zod');
const { loadConfig } = require('../utilities/config-loader');
const { extractParameters, initializeCourseIfNeeded, getServerTimestamp, getDatabaseRef } = require('../utilities/database-utils');
const { 
  AILongAnswerQuestionSchema, 
  AILongAnswerEvaluationSchema,
  LongAnswerFunctionParametersSchema 
} = require('../schemas/assessment-schemas');
const { applyPromptModules } = require('../prompt-modules');

// Environment variables
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;

// Initialize Genkit with Google AI plugin
const ai = genkit({
  plugins: [googleAI()],
  model: googleAI.model('gemini-2.0-flash'),
});

/**
 * Uses Genkit with structured outputs to generate a long answer question with rubric
 * @param {Object} config - Configuration object with prompts and settings
 * @param {string} topic - The question topic
 * @param {string} difficulty - The difficulty level (beginner, intermediate, advanced)
 * @param {Array} fallbackQuestions - Course-specific fallback questions
 * @returns {Promise<Object>} Generated question with rubric and sample answer
 */
async function generateAILongAnswerQuestion(config, topic, difficulty = 'intermediate', fallbackQuestions = []) {
  try {
    // Check if API key is available
    if (!GEMINI_API_KEY) {
      console.warn("No Gemini API key found. Using fallback question instead.");
      return getFallbackLongAnswerQuestion(difficulty, fallbackQuestions);
    }

    // Get the appropriate prompt template from config
    const prompts = config.prompts || {};
    const promptTemplate = prompts[difficulty] || prompts.intermediate || 
      `Create a long answer question about ${topic} at ${difficulty} level.`;
    
    // Apply conditional prompt modules as system instructions
    const systemInstructions = applyPromptModules(config);
    
    // Determine rubric configuration - use config hierarchy
    const rubricCriteria = config.rubricCriteria || 3;
    const totalPoints = config.totalPoints || 10;
    const wordLimits = config.wordLimits || { min: 50, max: 500 };
    
    // Create clean prompt content focused on the task
    const promptText = `${promptTemplate}

    REQUIREMENTS:
    1. Create a question that requires a detailed written response
    2. Design exactly ${rubricCriteria} rubric criteria that cover different aspects of understanding
    3. Distribute ${totalPoints} total points across the criteria (higher points for more important criteria)
    4. Make the rubric criteria clear, specific, and measurable
    5. Write a sample answer that would earn full points on all rubric criteria
    6. The sample answer should be between ${wordLimits.min} and ${wordLimits.max} words
    7. Ensure the question tests understanding, application, and critical thinking
    8. For physics questions, include opportunities to demonstrate mathematical reasoning where appropriate
    
    RUBRIC DESIGN:
    - Each criterion should focus on a different aspect of the answer
    - Descriptions should explain what is needed for full points
    - Points should reflect the relative importance of each criterion
    - Total points across all criteria must equal exactly ${totalPoints}`;
    
    console.log("Generating AI long answer question with structured output using Genkit");
    
    try {
      // Use Genkit's structured output with our Zod schema
      const generateOptions = {
        model: googleAI.model('gemini-2.0-flash'),
        prompt: promptText,
        output: { 
          schema: AILongAnswerQuestionSchema
        },
        config: {
          temperature: config.aiSettings?.temperature || 0.8,
          topP: config.aiSettings?.topP || 0.85,
          topK: config.aiSettings?.topK || 40
        }
      };
      
      // Add system instructions if we have prompt modules enabled
      if (systemInstructions && systemInstructions.trim().length > 0) {
        generateOptions.system = systemInstructions;
      }
      
      const { output } = await ai.generate(generateOptions);
      
      if (output == null) {
        console.error("Genkit returned null output for AI long answer question generation");
        throw new Error("Response doesn't satisfy schema.");
      }
      
      // Validate and adjust word limits if needed
      if (!output.wordLimit) {
        output.wordLimit = wordLimits;
      } else {
        output.wordLimit.min = output.wordLimit.min || wordLimits.min;
        output.wordLimit.max = Math.max(output.wordLimit.max || wordLimits.max, wordLimits.max);
      }
      
      // Validate total points match configuration
      const actualTotal = output.rubric.reduce((sum, criterion) => sum + criterion.points, 0);
      if (actualTotal !== output.maxPoints) {
        console.warn(`Rubric total (${actualTotal}) doesn't match maxPoints (${output.maxPoints}). Adjusting...`);
        output.maxPoints = actualTotal;
      }
      
      console.log("Successfully generated AI long answer question with rubric:", 
        output.questionText.substring(0, 50) + "...");
      
      return {
        ...output,
        generatedBy: 'ai'
      };
      
    } catch (err) {
      console.error("Error with Genkit AI generation:", err.message);
      console.log("Falling back to predefined question due to AI generation error");
      return getFallbackLongAnswerQuestion(difficulty, fallbackQuestions);
    }
  } catch (error) {
    console.error("Error generating AI long answer question:", error);
    return getFallbackLongAnswerQuestion(difficulty, fallbackQuestions);
  }
}

/**
 * Gets a fallback long answer question from course-specific fallbacks or defaults
 * @param {string} difficulty - The difficulty level
 * @param {Array} fallbackQuestions - Course-specific fallback questions
 * @returns {Object} A fallback question
 */
function getFallbackLongAnswerQuestion(difficulty = 'intermediate', fallbackQuestions = []) {
  // First try course-specific fallbacks
  const filteredFallbacks = fallbackQuestions.filter(q => q.difficulty === difficulty);
  const availableFallbacks = filteredFallbacks.length > 0 ? filteredFallbacks : 
    fallbackQuestions.filter(q => q.difficulty === 'intermediate');
  
  if (availableFallbacks.length > 0) {
    const randomIndex = Math.floor(Math.random() * availableFallbacks.length);
    const selectedQuestion = availableFallbacks[randomIndex];
    
    return {
      ...selectedQuestion,
      generatedBy: 'fallback'
    };
  }
  
  // If no fallbacks available, return a generic question
  return {
    questionText: "This is a placeholder long answer question. Please provide course-specific fallback questions.",
    rubric: [
      {
        criterion: "Understanding",
        points: 4,
        description: "Demonstrates understanding of key concepts"
      },
      {
        criterion: "Application",
        points: 4,
        description: "Applies concepts to solve problems"
      },
      {
        criterion: "Communication",
        points: 2,
        description: "Communicates ideas clearly"
      }
    ],
    maxPoints: 10,
    wordLimit: { min: 50, max: 300 },
    sampleAnswer: "This is a placeholder sample answer. Course developers should provide fallback questions with proper sample answers.",
    generatedBy: 'placeholder'
  };
}

/**
 * Uses Genkit to evaluate a student's long answer against the rubric
 * @param {Object} question - The question object with rubric
 * @param {string} studentAnswer - The student's answer
 * @param {string} sampleAnswer - The sample answer for reference
 * @returns {Promise<Object>} Evaluation result with scores and feedback
 */
async function evaluateAILongAnswer(question, studentAnswer, sampleAnswer) {
  try {
    if (!GEMINI_API_KEY) {
      console.warn("No Gemini API key found. Using fallback evaluation.");
      return getFallbackEvaluation(question, studentAnswer);
    }

    // Count words in student answer
    const wordCount = studentAnswer.trim().split(/\s+/).filter(word => word.length > 0).length;
    
    // Create evaluation prompt
    const evaluationPrompt = `You are evaluating a student's answer to the following question:

QUESTION: ${question.questionText}

STUDENT ANSWER (${wordCount} words):
${studentAnswer}

SAMPLE ANSWER FOR REFERENCE:
${sampleAnswer}

SCORING RUBRIC:
${question.rubric.map((criterion, index) => 
  `${index + 1}. ${criterion.criterion} (${criterion.points} points): ${criterion.description}`
).join('\n')}

TOTAL POINTS: ${question.maxPoints}

Please evaluate the student's answer according to each rubric criterion. For each criterion:
1. Assign a score from 0 to the maximum points for that criterion
2. Provide specific feedback explaining why that score was given
3. Reference specific parts of the student's answer when possible

Also provide:
- Overall feedback summarizing the quality of the answer
- 2-3 key strengths in the answer (if any)
- 2-3 specific suggestions for improvement
- A brief suggestion on how to improve for next time

Be fair but thorough in your evaluation. Give partial credit where appropriate.`;

    const systemInstructions = `You are an expert ${question.subject || 'subject'} teacher evaluating student work. 
Be constructive and encouraging while maintaining high standards. 
Focus on both what the student did well and areas for improvement.
${applyPromptModules({ katexFormatting: true })}`;

    console.log("Evaluating student long answer with AI");

    // Use Genkit's structured output for evaluation
    const { output } = await ai.generate({
      model: googleAI.model('gemini-2.0-flash'),
      prompt: evaluationPrompt,
      system: systemInstructions,
      output: { 
        schema: AILongAnswerEvaluationSchema
      },
      config: {
        temperature: 0.3, // Lower temperature for more consistent evaluation
        topP: 0.8,
        topK: 40
      }
    });

    if (!output) {
      throw new Error("AI evaluation returned no output");
    }

    // Validate total score matches sum of rubric scores
    const calculatedTotal = output.rubricScores.reduce((sum, score) => sum + score.score, 0);
    if (Math.abs(calculatedTotal - output.totalScore) > 0.1) {
      console.warn(`Total score mismatch: calculated ${calculatedTotal}, reported ${output.totalScore}`);
      output.totalScore = calculatedTotal;
    }

    // Calculate percentage
    output.percentage = Math.round((output.totalScore / output.maxScore) * 100);

    console.log(`AI evaluation complete: ${output.totalScore}/${output.maxScore} (${output.percentage}%)`);

    return output;

  } catch (error) {
    console.error("Error evaluating long answer with AI:", error);
    return getFallbackEvaluation(question, studentAnswer);
  }
}

/**
 * Provides a simple fallback evaluation when AI is unavailable
 * @param {Object} question - The question object
 * @param {string} studentAnswer - The student's answer
 * @returns {Object} Basic evaluation result
 */
function getFallbackEvaluation(question, studentAnswer) {
  const wordCount = studentAnswer.trim().split(/\s+/).filter(word => word.length > 0).length;
  const hasAnswer = wordCount >= (question.wordLimit?.min || 50);
  
  // Simple scoring: give partial credit if answer meets minimum length
  const baseScore = hasAnswer ? 0.5 : 0.2;
  
  return {
    totalScore: Math.round(question.maxPoints * baseScore),
    maxScore: question.maxPoints,
    percentage: Math.round(baseScore * 100),
    overallFeedback: hasAnswer 
      ? "Your answer has been recorded. Detailed evaluation is currently unavailable."
      : "Your answer is too short. Please provide a more detailed response.",
    rubricScores: question.rubric.map(criterion => ({
      criterion: criterion.criterion,
      score: Math.round(criterion.points * baseScore),
      maxPoints: criterion.points,
      feedback: "Automated evaluation unavailable. Please consult your instructor."
    })),
    suggestions: "For detailed feedback, please contact your instructor."
  };
}

/**
 * Infers activity type from assessment ID patterns
 * @param {string} assessmentId - The assessment identifier
 * @returns {string} The inferred activity type
 */
function inferActivityTypeFromAssessmentId(assessmentId) {
  if (!assessmentId) return 'assignment';
  
  const id = assessmentId.toLowerCase();
  
  if (id.includes('assignment') || id.includes('homework') || id.includes('hw')) {
    return 'assignment';
  } else if (id.includes('exam') || id.includes('test') || id.includes('final')) {
    return 'exam';
  } else if (id.includes('lab') || id.includes('laboratory') || id.includes('experiment')) {
    return 'lab';
  } else if (id.includes('lesson') || id.includes('practice')) {
    return 'lesson';
  } else {
    return 'assignment'; // Default for long answer
  }
}

/**
 * Factory function to create an AI Long Answer assessment handler
 * @param {Object} courseConfig - Course-specific configuration
 * @returns {Function} Cloud function handler
 */
function createAILongAnswer(courseConfig = {}) {
  return onCall({
    region: courseConfig.region || 'us-central1',
    timeoutSeconds: courseConfig.timeout || 120, // Longer timeout for evaluation
    memory: courseConfig.memory || '1GiB', // More memory for text processing
    enforceAppCheck: false,
  }, async (data, context) => {
    // Load and merge configurations
    const globalConfig = await loadConfig();
    
    // SECURITY: Use hardcoded activity type from course config
    const activityType = courseConfig.activityType || inferActivityTypeFromAssessmentId(data.assessmentId) || 'assignment';
    
    console.log(`Using activity type: ${activityType} (Source: ${courseConfig.activityType ? 'hardcoded' : 'inferred'})`);
    
    // Get activity-specific configuration
    const activityConfig = courseConfig.activityTypes?.[activityType] || courseConfig.activityTypes?.assignment || {};
    
    // Get long answer specific settings from activity config
    const longAnswerDefaults = activityConfig.longAnswer || {};
    
    const config = {
      ...globalConfig.questionTypes?.longAnswer?.ai_generated || {},
      ...activityConfig,
      ...longAnswerDefaults, // Apply long answer defaults from course config
      ...courseConfig // Allow courseConfig to override if needed
    };

    // Extract and validate parameters
    const params = extractParameters(data, context, LongAnswerFunctionParametersSchema);

    // Initialize course if needed
    await initializeCourseIfNeeded(params.studentKey, params.courseId);

    // Reference to the assessment in the database
    const assessmentRef = getDatabaseRef('studentAssessment', params.studentKey, params.courseId, params.assessmentId);
    console.log(`Database path: students/${params.studentKey}/courses/${params.courseId}/Assessments/${params.assessmentId}`);

    // Handle question generation operation
    if (params.operation === 'generate') {
      try {
        // Check if this is a regeneration or a new assessment
        const existingAssessmentSnapshot = await assessmentRef.once('value');
        const existingAssessment = existingAssessmentSnapshot.val();
        const isRegeneration = !!existingAssessment;
        
        // Initialize the attempts counter
        let currentAttempts = 0;
        if (existingAssessment) {
          currentAttempts = existingAssessment.attempts || 0;
        }
        
        console.log(`This is a ${isRegeneration ? 'regeneration' : 'new question'} request. Current attempts: ${currentAttempts}`);
        
        // Determine max attempts - use the same value as course config for multiple choice
        let maxAttempts = config.maxAttempts || activityConfig.maxAttempts || 3; // Default 3 for long answer
        
        console.log(`Max attempts allowed: ${maxAttempts}`);
        
        // Verify the student hasn't exceeded the max attempts
        if (isRegeneration && currentAttempts >= maxAttempts) {
          console.log(`Security check: Student has exceeded max attempts (${currentAttempts}/${maxAttempts})`);
          throw new Error(`Maximum attempts (${maxAttempts}) reached for this assessment.`);
        }
        
        // Generate the AI long answer question
        console.log(`Generating AI long answer question on topic: ${params.topic}, difficulty: ${params.difficulty}`);
        const question = await generateAILongAnswerQuestion(
          config,
          params.topic,
          params.difficulty,
          courseConfig.fallbackQuestions || []
        );
        
        // Create the final question data object to save
        const questionData = {
          timestamp: getServerTimestamp(),
          questionText: question.questionText,
          rubric: question.rubric,
          maxPoints: question.maxPoints,
          wordLimit: question.wordLimit,
          topic: params.topic,
          difficulty: params.difficulty,
          generatedBy: question.generatedBy || 'ai',
          attempts: currentAttempts,
          status: 'active',
          maxAttempts: maxAttempts,
          activityType: activityType,
          enableAIChat: config.enableAIChat,
          aiChatContext: config.aiChatContext,
          settings: {
            showRubric: config.showRubric !== undefined ? config.showRubric : (longAnswerDefaults.showRubric !== undefined ? longAnswerDefaults.showRubric : true),
            showWordCount: config.showWordCount !== undefined ? config.showWordCount : (longAnswerDefaults.showWordCount !== undefined ? longAnswerDefaults.showWordCount : true),
            showHints: config.showHints === true || activityConfig.enableHints === true,
            allowDifficultySelection: config.allowDifficultySelection || activityConfig.allowDifficultySelection || false,
            theme: config.theme || activityConfig.theme || 'purple',
          }
        };
        
        // Store public question data in the database (student-accessible)
        await assessmentRef.set(questionData);

        // Store the secure data separately (server-side only)
        const secureRef = getDatabaseRef('secureAssessment', params.courseId, params.assessmentId);
        
        await secureRef.set({
          sampleAnswer: question.sampleAnswer,
          hints: question.hints || [],
          timestamp: getServerTimestamp()
        });

        return {
          success: true,
          questionGenerated: true,
          assessmentId: params.assessmentId,
          generatedBy: question.generatedBy
        };
      } catch (error) {
        console.error("Error generating AI long answer question:", error);
        throw new Error('Error generating question: ' + error.message);
      }
    }
    // Handle answer evaluation operation
    else if (params.operation === 'evaluate') {
      try {
        // Get the existing question data
        const assessmentSnapshot = await assessmentRef.once('value');
        const assessmentData = assessmentSnapshot.val();

        if (!assessmentData) {
          throw new Error('Assessment not found');
        }
        
        // Check max attempts
        const maxAttempts = assessmentData.maxAttempts || 3;
        
        if (assessmentData.attempts >= maxAttempts) {
          console.log(`Security check: Student has exceeded max attempts (${assessmentData.attempts}/${maxAttempts})`);
          return {
            success: false,
            error: 'Maximum attempts exceeded',
            attemptsRemaining: 0
          };
        }

        // Get the secure data
        const secureRef = getDatabaseRef('secureAssessment', params.courseId, params.assessmentId);
        const secureSnapshot = await secureRef.once('value');
        const secureData = secureSnapshot.val();

        if (!secureData || !secureData.sampleAnswer) {
          throw new Error('Secure assessment data not found');
        }

        // Validate answer length
        const wordCount = params.answer.trim().split(/\s+/).filter(word => word.length > 0).length;
        const wordLimit = assessmentData.wordLimit || { min: 50, max: 500 };
        
        if (wordCount < (wordLimit.min || 0)) {
          throw new Error(`Answer too short. Minimum ${wordLimit.min} words required, you wrote ${wordCount} words.`);
        }
        
        if (wordCount > (wordLimit.max || 5000)) {
          throw new Error(`Answer too long. Maximum ${wordLimit.max} words allowed, you wrote ${wordCount} words.`);
        }

        // Evaluate the answer using AI
        const evaluation = await evaluateAILongAnswer(
          assessmentData,
          params.answer,
          secureData.sampleAnswer
        );

        // Increment attempts
        let updatedAttempts = (assessmentData.attempts || 0) + 1;
        console.log(`Incrementing attempts from ${assessmentData.attempts || 0} to ${updatedAttempts}`);
        
        const attemptsRemaining = maxAttempts - updatedAttempts;

        // Prepare the submission record
        const submission = {
          timestamp: getServerTimestamp(),
          answer: params.answer,
          wordCount: wordCount,
          evaluation: evaluation,
          attemptNumber: updatedAttempts
        };

        // Update assessment data in the database
        const updates = {
          attempts: updatedAttempts,
          status: evaluation.percentage >= 70 ? 'completed' : (attemptsRemaining > 0 ? 'attempted' : 'failed'),
          lastSubmission: submission
        };

        // Add submission to history
        await assessmentRef.child('submissions').push(submission);

        // Update the assessment
        await assessmentRef.update(updates);

        // Update the grade
        const gradeRef = getDatabaseRef('studentGrade', params.studentKey, params.courseId, params.assessmentId);
        
        // For long answer, we might want to store the percentage or scaled score
        const gradeValue = evaluation.totalScore; // Or use evaluation.percentage / 10 for a 0-10 scale
        
        await gradeRef.set(gradeValue);

        return {
          success: true,
          result: evaluation,
          attemptsRemaining: attemptsRemaining,
          attemptsMade: updatedAttempts
        };
      } catch (error) {
        console.error("Error evaluating answer:", error);
        throw new Error('Error evaluating answer: ' + error.message);
      }
    }

    // Invalid operation
    throw new Error('Invalid operation. Supported operations are "generate" and "evaluate".');
  });
}

module.exports = {
  createAILongAnswer
};